{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65e4fae4",
   "metadata": {},
   "source": [
    "Below you can find the code to import data from niania.pl website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eb9c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12637b9b",
   "metadata": {},
   "source": [
    "how many pages nianiapl has for chosen location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb21d2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a8f134",
   "metadata": {},
   "source": [
    "create set to store offer links:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f80b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a28cf9",
   "metadata": {},
   "source": [
    "create dictionary from which we will create df later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca516b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "slownik = {'date': [], 'adres': [], 'wynagrodzenie': [], 'etat': [], 'autor': [], 'doswiadczenie': [],\n",
    "           'wiek_niani': [], 'dodatkowe_wymagania': [], 'jezyk1': [], 'jezyk2':[], 'dzieci': [],\n",
    "           'liczba_dzieci': []}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e962c9a",
   "metadata": {},
   "source": [
    "getting all links and adding offer links:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bba98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in range(1, pages+1):\n",
    "    page_link = f'''https://niania.pl/praca/warszawa?page={page}'''\n",
    "    response = requests.get(page_link)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    tags = soup('a')\n",
    "\n",
    "    for tag in tags:\n",
    "        offer_link = tag.get('href',None)  \n",
    "        if type(offer_link) == str and offer_link.startswith('https://niania.pl/szukam/'):\n",
    "            links.add(offer_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42b93b5",
   "metadata": {},
   "source": [
    "how many offers do we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281b8206",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'number of offers: ', len(links))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3900b71",
   "metadata": {},
   "source": [
    "iterate through each offer to create connection with every page and get necessary data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42457c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in links:\n",
    "\n",
    "    response = requests.get(link)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    soup_str = str(soup)\n",
    "\n",
    "    lista = soup.find('ul', class_=\"list-style-none summary\")\n",
    "    lista_oczekiwania = soup.find_all('li', class_=\"pico-tick-before\")\n",
    "\n",
    "    jezyki = soup.find_all('li', class_='pb-3 icon-lang-polish-before')\n",
    "\n",
    "    try: #first languge\n",
    "        jezyk1 = jezyki[0].get_text().strip()\n",
    "    except Exception:\n",
    "        jezyk1 = ' '\n",
    "\n",
    "    try: #second languge\n",
    "        jezyk2 = jezyki[1].get_text().strip()\n",
    "    except Exception:\n",
    "        jezyk2 = ' '\n",
    "\n",
    "    try: #nannys preferred age\n",
    "        wiek_niani = lista_oczekiwania[3].find(\"strong\").get_text()\n",
    "    except Exception:\n",
    "        wiek_niani = ' '\n",
    "\n",
    "    try: #advertisement author\n",
    "        autor = lista.select(\"li:nth-of-type(7)\")[0].find(\"strong\").get_text()\n",
    "    except Exception:\n",
    "        autor = ' '\n",
    "\n",
    "    try: #nannys exeprience\n",
    "        doswiadczenie = lista_oczekiwania[2].find(\"strong\").get_text()\n",
    "    except Exception:\n",
    "        doswiadczenie = ' '\n",
    "\n",
    "    try: #date\n",
    "        data_dodania = soup.find('time').get_text()\n",
    "    except Exception:\n",
    "        data_dodania = ' '\n",
    "\n",
    "    try: #adress\n",
    "        adres = lista.select(\"li:nth-of-type(5)\")[0].find(\"span\").get_text()\n",
    "    except Exception:\n",
    "        adres = ' '\n",
    "\n",
    "    try: #salary\n",
    "        wynagrodzenie = lista.select(\"li:nth-of-type(4)\")[0].find(\"span\").get_text()\n",
    "    except Exception:\n",
    "        wynagrodzenie = ' '\n",
    "\n",
    "    etat = lista.select(\"li:nth-of-type(3)\")[0].find_all(\"span\")\n",
    "    e = [etat.get_text() for etat in etat]\n",
    "    etat_lista = [e.strip() for e in e] # type of job\n",
    "\n",
    "    dodatki = [] # extra requirements:\n",
    "\n",
    "    for element in range(4, len(lista_oczekiwania)):\n",
    "        dodatek = lista_oczekiwania[element].get_text().splitlines()\n",
    "        d = ' '.join(dodatek)\n",
    "        d = d.strip()\n",
    "        dodatki.append(d)\n",
    "\n",
    "    dziecko = soup.find_all('li', class_='pb-2')\n",
    "\n",
    "    liczba_dzieci = len(dziecko) #number of children\n",
    "    dzieci = []\n",
    "\n",
    "    if len(dziecko) > 1:\n",
    "        for element in range(0, len(dziecko)):\n",
    "            p = dziecko[element-1].get_text()\n",
    "            pp = p.strip()\n",
    "            dzieci.append(pp)\n",
    "    else:\n",
    "        dd = dziecko[0].get_text()\n",
    "        ddd = dd.strip()\n",
    "        dzieci.append(ddd)\n",
    "\n",
    "    # data gathering:\n",
    "\n",
    "    lista_naglowkow = ['date', 'adres', 'wynagrodzenie', 'etat', 'autor', 'doswiadczenie', 'wiek_niani', 'dodatkowe_wymagania',\n",
    "                       'jezyk1', 'jezyk2', 'dzieci', 'liczba_dzieci']\n",
    "\n",
    "    dane = [data_dodania, adres, wynagrodzenie, etat_lista, autor, doswiadczenie, wiek_niani, dodatki,\n",
    "            jezyk1, jezyk2, dzieci, liczba_dzieci]\n",
    "\n",
    "    for value in range(0, len(dane)):\n",
    "        try:\n",
    "            slownik[lista_naglowkow[value]].append(dane[value])\n",
    "        except Exception:\n",
    "            slownik[lista_naglowkow[value]].append('NaN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a2375e",
   "metadata": {},
   "source": [
    "creating df with all data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92210188",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(slownik)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454aea67",
   "metadata": {},
   "source": [
    "creating csv from df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8b014a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('niania_pl_final.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
